{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eel imports\n",
    "\n",
    "Now let's take a look at a cut of data on eel product imports. The data come from [a foreign trade database maintained by NOAA](https://www.st.nmfs.noaa.gov/commercial-fisheries/foreign-trade/).\n",
    "\n",
    "The CSV file lives here: `../data/eels.csv`.\n",
    "\n",
    "We'll start by importing pandas and creating a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output with `head()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the values\n",
    "\n",
    "Now let's poke through the values in each column to see what we're working with using a combination of `unique()`, `min()` and `max()`. Questions we're trying to answer here: What years and months are represented? What countries are in the data? Do the numeric data make sense? Are there any obvious errors or typos to handle? Are there any holes in our data (use `info()`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output with `info()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the years with `unique()` to see what's in there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with months ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the country column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the product column -- have to use bracket notation bc \"product\" is a pandas function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What does \"ATC\" stand for? _Always ask, never assume._\n",
    "\n",
    "![atc](../img/eel-q.png \"atc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `min()` and `max()` kilos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `min()` and `max()` dollars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series data: Check for completeness\n",
    "\n",
    "Each row in our data is one month's worth of shipments of a particular eel product from a particular country to the U.S. Which means we might want to do some time-based comparisons, so we need to check that we're dealing with complete years.\n",
    "\n",
    "So first let's think about what we want to see: For each year that's present in our data, we want a unique list of months for those records. If we were in Excel, we might pivot to group the data by `year` and then throw `month` in the \"columns\" section to see what months are present for each year.\n",
    "\n",
    "Here, we're going to do something similar:\n",
    "- Select just the columns we're interested in\n",
    "- Use the pandas `groupby()` method to group the records by year\n",
    "- For each set of grouped data, use the pandas `unique()` method on the month column to see what months are present\n",
    "\n",
    "When we call `groupby()` on a data frame, it returns a collection of items; each item in that collection is a Python data container with two elements: the _grouping_ value (year, in this case) and a dataframe of records that belong to that group (all records where year == that year).\n",
    "\n",
    "So we can use a _for loop_ to iterate over the results and check each year.\n",
    "\n",
    "ðŸ‘‰For more details on _for loops_, [see this notebook](../appendix/Python%20data%20types%20and%20basic%20syntax.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab year and month data and group by year\n",
    "\n",
    "# loop over that grouped object\n",
    "\n",
    "    # and print the grouping value plus a list of unique months\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know that we have incomplete data for 2017 -- _news we can use_ as we start our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Come up with a list of questions\n",
    "\n",
    "- In this data, what country ships the most eel products of any type to the U.S.?\n",
    "- Same question but broken out by year.\n",
    "- For each country, what was the percent change in eel shipments of all types from 2010-2016?\n",
    "- What type of product is most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Who ships the most eels to the U.S. (in kilos)?\n",
    "\n",
    "We'll use our good friends `groupby()`, `sum()` and `sort_values()`to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select country and kilos data, group by country, sum and sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Who ships the most? (Broken out by year)\n",
    "\n",
    "Now we want to create a table where the rows are countries, the columns are years, and the values are sums for that country, that year.\n",
    "\n",
    "If we were doing this in an Excel pivot table, we'd just add \"year\" to the columns section. To do this in pandas, we're ... also going to use a pivot table. (Yes! Pandas has a [pivot table function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html).)\n",
    "\n",
    "We are going to hand the `pivot_table()` function five arguments:\n",
    "1. The data we're pivoting (`df`)\n",
    "2. The name of the column whose values we're doing math on (`values='kilos'`)\n",
    "3. The type of aggregation to apply to the values -- default is `mean` and we do not want that (`aggfunc='sum'`)\n",
    "4. The name of the column we're grouping on (`index='country'`)\n",
    "5. The name of the column whose values will become the columns of our table (`columns='year'`)\n",
    "\n",
    "Optionally, we can then use `sort_values()` to sort the pivot table that results by our most recent year of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a pivot table to get most shipments broken out by year\n",
    "\n",
    "# sort values by the latest year (2017) and sort descending\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What was the percent change in shipments for each country from 2010-2016?\n",
    "\n",
    "For this question, we'll re-use the pivot table we just made and add a calculated column. First, though, we need to filter the table to include only records where the `2010` and `2016` values are not null, using the [`notnull()` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.notnull.html). (Looks like just filtering for \"2010 is not null\" does the trick.)\n",
    "\n",
    "**If you didn't know about `.notnull()` already, how would you Google to find the answer?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the pivoted data to get only countries that had a non-null value in 2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add a column -- `10to16pctchange`. The syntax, and the math -- new value minus old value divided by old value -- are relatively straightforward: \n",
    "\n",
    "`dataframe['new_column'] = (dataframe['new_value'] - dataframe['old_value']) / dataframe['old_value'] * 100`\n",
    "\n",
    "You might get a warning about slices vs. copies. You can ignore that for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a calculated column to calculate the percent change over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values by our new column descending\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What type of product is most popular (in kilos)?\n",
    "\n",
    "We'll use `groupby()`, `sum()` and `sort_values()` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select product and kilos, group by product, sum and sort by kilos descending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What other questions do you want to explore?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
