{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Eel imports\n",
    "\n",
    "Now let's take a look at a cut of data on eel product imports. The data come from [a foreign trade database maintained by NOAA](https://www.st.nmfs.noaa.gov/commercial-fisheries/foreign-trade/).\n",
    "\n",
    "The CSV file lives here: `../data/eels.csv`.\n",
    "\n",
    "We'll start by importing pandas and creating a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/eels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the values\n",
    "\n",
    "Now let's poke through the values in each column to see what we're working with using a combination of `unique()`, `min()` and `max()`. Questions we're trying to answer here: What years and months are represented? What countries are in the data? Do the numeric data make sense? Are there any obvious errors or typos to handle? Are there any holes in our data (use `info()`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to use bracket notation bc \"product\" is a pandas function\n",
    "df['product'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What does \"ATC\" stand for? _Always ask, never assume._\n",
    "\n",
    "![atc](../img/eel-q.png \"atc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.kilos.max())\n",
    "print(df.kilos.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dollars.max())\n",
    "print(df.dollars.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series data: Check for completeness\n",
    "\n",
    "Each row in our data is one month's worth of shipments of a particular eel product from a particular country to the U.S. Which means we might want to do some time-based comparisons, so we need to check that we're dealing with complete years.\n",
    "\n",
    "So first let's think about what we want to see: For each year that's present in our data, we want a unique list of months for those records. If we were in Excel, we might pivot to group the data by `year` and then throw `month` in the \"columns\" section to see what months are present for each year.\n",
    "\n",
    "Here, we're going to do something similar:\n",
    "- Select just the columns we're interested in\n",
    "- Use the pandas `groupby()` method to group the records by year\n",
    "- For each set of grouped data, use the pandas `unique()` method on the month column to see what months are present\n",
    "\n",
    "When we call `groupby()` on a data frame, it returns a list of items; each item in that list is a Python data container with two elements: the _grouping_ value (year, in this case) and a dataframe of records that belong to that group (all records where year == that year).\n",
    "\n",
    "So we can use a _for loop_ to iterate over the results and check each year.\n",
    "\n",
    "ðŸ‘‰For more details on _for loops_, [see this notebook](../appendix/Python%20data%20types%20and%20basic%20syntax.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yeargroup in df[['year', 'month']].groupby('year'):\n",
    "    print(yeargroup[0], yeargroup[1].month.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know that we have incomplete data for 2017 -- news we can use as we start our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Come up with a list of questions\n",
    "\n",
    "- In this data, what country ships the most eel products of any type to the U.S.?\n",
    "- Same question but broken out by year.\n",
    "- For each country, what was the percent change in eel shipments of all types from 2010-2016?\n",
    "- What type of product is most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Who ships the most eels to the U.S. (in kilos)?\n",
    "\n",
    "We'll use our good friends `groupby()`, `sum()` and `sort_values()`to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['country', 'kilos']].groupby('country') \\\n",
    "                        .sum() \\\n",
    "                        .sort_values('kilos', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Who ships the most? (Broken out by year)\n",
    "\n",
    "Now we want to create a table where the rows are countries, the columns are years, and the values are sums for that country, that year.\n",
    "\n",
    "If we were doing this in an Excel pivot table, we'd just add \"year\" to the columns section. To do this in pandas, we're ... also going to use a pivot table. (Yes! Pandas has a [pivot table function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html).)\n",
    "\n",
    "We are going to hand the `pivot_table()` function five arguments:\n",
    "1. The data we're pivoting (`df`)\n",
    "2. The name of the column whose values we're doing math on (`values='kilos'`)\n",
    "3. The type of aggregation to apply to the values -- default is 'mean' (`aggfunc='sum'`)\n",
    "4. The name of the column we're grouping on (`index='country'`)\n",
    "5. The name of the column whose values will become the columns of our table (`columns='year'`)\n",
    "\n",
    "Optionally, we can then use `sort_values()` to sort the pivot table that results by our most recent year of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_sums = pd.pivot_table(df,\n",
    "                              aggfunc='sum',\n",
    "                              values='kilos',\n",
    "                              index='country',\n",
    "                              columns='year')\n",
    "\n",
    "pivoted_sums.sort_values(2017, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What was the percent change in shipments for each country from 2010-2016?\n",
    "\n",
    "For this question, we'll re-use the pivot table we just made and add a calculated column. First, though, we need to filter the table to include only records where the `2010` and `2016` values are not null, using the [`notnull()` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.notnull.html). (Looks like just filtering for \"2010 is not null\" does the trick.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_sums_notnull = pivoted_sums[pivoted_sums[2010].notnull()]\n",
    "\n",
    "pivoted_sums_notnull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add a column -- `10to16pctchange`. The syntax, and the math -- new value minus old value divided by old value -- are relatively straightforward: \n",
    "\n",
    "`dataframe['new_column'] = (dataframe['new_value'] - dataframe['old_value']) / dataframe['old_value'] * 100`\n",
    "\n",
    "You might get a warning about slices vs. copies. You can ignore that for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_sums_notnull['10to16pctchange'] = (pivoted_sums_notnull[2016] - pivoted_sums_notnull[2010]) / pivoted_sums_notnull[2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_sums_notnull.sort_values('10to16pctchange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What type of product is most popular (in kilos)?\n",
    "\n",
    "We'll use `groupby()`, `sum()` and `sort_values()` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_products = df[['product', 'kilos']].groupby('product') \\\n",
    "                                       .sum() \\\n",
    "                                       .sort_values('kilos', ascending=False)\n",
    "pop_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What other questions do you want to explore?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
